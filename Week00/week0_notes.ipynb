{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How we do things with words: Analyzing text as social and cultural data\n",
    "\n",
    "*Dong Nguyen, Maria Liakata, Simon DeDeo, Jacob Eisenstein, David Mimno, Rebekah Tromble, and Jane Winters*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Choices regarding how to operationalize and analyze these concepts (such as hate speech in social media) can raise serioius concerns about conceptual validity and may lead to shallow or obvious conclusions, rather than findings that reflect the depth of the questions we seek to address.\"\n",
    "\n",
    "Reading Framework:\n",
    "\n",
    "* identification of research questions;\n",
    "* data selection;\n",
    "* conceptualization and operationalization;\n",
    "* analysis and interpretation.\n",
    "\n",
    "Goals of the reading:\n",
    "\n",
    "* \"shed light on thorny issues not always at the forefront of discussions about computational text analysis;\n",
    "* provide a set of best practices for workign with thick social and cultural concepts;\n",
    "* and to help promote interdisciplinary collaborations.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESEARCH QUESTIONS\n",
    "\n",
    "* How some phenomena in language has changed over time\n",
    "* How do you set boundries that define a particular phenomena\n",
    "* prediction analysis vs. perfect labeling\n",
    "* \"dual use\" concerns creating a tool to analyze a problem of social concern could then be co-opted by users for malicious intentions\n",
    "* Engaging reviews versus dialogue\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA\n",
    "\n",
    "##### Data Aquisition\n",
    "* Consent and similar concerns of \"dual use\" and or malicious uses for \"born-digital\" data, big social networks have clamped down their APIs as a result, even being reticent about academic researchers' access.\n",
    "* Provenance and contextualisation (reference data feminism on the tendency for marginalized groups' data and perspectives are excluded from the data set creation process)\n",
    "* Limited access to \"black box\" APIs that generate data sets (such as search results) and the biases that exisit in the API cannot be examined.\n",
    "\n",
    "##### Compiling Data\n",
    "* Involves making sense of \"cleaning\" data processes. Are simply meta data, duplicates, or non-study specific data being removed or are we affecting interpretation by removing data that might be relevant but is simply difficult to use because it is noisy and/or needs a lot of individualized attention to make it usable.\n",
    "* Examining metadata can illuminate potential inconsistencies and biases in data sets. For example: does the data set have a particular weighted focus or are particular time periods emphasized over others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCEPTUALIZATION\n",
    "\n",
    "* \"translating social and cultural concepts into measurable quantities;\"\n",
    "* Need to define domain experts and look at previous approaches to analysis;\n",
    "* \"Background Concept\" – full and diverse set of meanings that might be associated with a particular term. Past research and definitions can help determine what is the most appropriate definition to be used for the study;\n",
    "* \"Systematized Concept\" is the arrived at formulation for the study. And frames the study in a particular context and does not presume any absolute truthfulness in the chosen path. This pushes against ideas of a \"ground truth\" or \"gold standard\" supposedly arrived at in many a machine learning model;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPERATIONALIZATION\n",
    "\n",
    "Labeling and scoring proecesses\n",
    "\n",
    "#### Modeling considerations\n",
    "\n",
    "* Variable types and definitions – categories and boundries;\n",
    "* Categorization schemes – issues with binaries and other limitations;\n",
    "* Supervised vs. unsupervised – supervised for when we know what we're looking for vs. when we are looking to build topic models;\n",
    "* Units of interest – How to breakdown the text object: by story, sentence, phrase, bi-gram, n-gram of one, etc...\n",
    "* Interpretability – models that can easily communicate\n",
    "\n",
    "#### Annotation\n",
    "\n",
    "* Human coders to train an annotation model that is then applied larger data sets for analysis;\n",
    "* Annotation choices are thought of as the \"codebook;\"\n",
    "* Who are the annotators and what skill level is required for the process;\n",
    "* Disagreement between annotators can signal weaknesses in the codebook or illuminate a need for a more meaningful approach to future analysis.\n",
    "\n",
    "#### Data pre-processing\n",
    "\n",
    "* important to document whatever processes were undertaken to prepare and re-structure data before the analysis is applied;\n",
    "* OCR errors as an example – they can vary within a corpus and over time as the quality of the OCR toolset has evolved.\n",
    "* Tokenization processes don't do well with emoji, creative orthography (sh!t, U$A), and missing spaces.\n",
    "* Lots of other processes to consider – lowercasing, removing punctuation, stemming (removing suffixes), lemmatization, normalization (groupings of similar words and/or abbreviations);\n",
    "* Stop word lists;\n",
    "* What guides the choices in these processing steps...\n",
    "\n",
    "#### Dictionary-based approaches\n",
    "\n",
    "* word lists used for scoring\n",
    "\n",
    "#### Supervised models\n",
    "\n",
    "* An example is to create a classifier based on a small set of annotations and then apply it to a larger set;\n",
    "* Definition and label types are of great consequence;\n",
    "* Features of the model are the \"abilities\" of the model – content-based single words, sequences of words, insight models, word embeddings;\n",
    "* Concerns include issues of how the model might interact with particular datasets that are not well-balanced, or has noisy annotations;\n",
    "* Spurious features and the need for interpretability – survey data that needs to be interpreted based on the unbalanced response rates;\n",
    "\n",
    "#### Topic modeling\n",
    "\n",
    "* usually unsupervised;\n",
    "* \"creates a set of probability distributions over the vocabulary of the collection, which, when combined toghether in different proportions, best match the contnet of the collection;\"\n",
    "* the probabilities of words then can give a sense of what the topic is \"about;\"\n",
    "* there may be a need to manage stopword lists if there is a need to improve language filtering.\n",
    "\n",
    "#### Validation\n",
    "\n",
    "* How good is our \"scoring\" system – is it validly measuring what it's supposed to measure;\n",
    "* Comparing machine generated result to a human annotated example;\n",
    "* Accuracy and measures of precision, such as F-scores, are sometimes used, but often it's a better measure of accuracy then validity;\n",
    "* Good to have additional forms of validation, such as close readings basic observations of the 'sensibility' of the results;\n",
    "* Validation through comparison to other approaches to the same concept;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS\n",
    "\n",
    "* Using our models to explore answers to our research questions;\n",
    "* \"Errors\" may provide insights into future studies;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bffae61b4a647f5c3a2b9689cc2bbc523f2c1227093a073b0d809d31c71c3583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
