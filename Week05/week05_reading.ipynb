{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender and Cultural Analytics: Finding or Making Stereotypes?\n",
    "*Mandell, Laura*\n",
    "\n",
    "Laura Mandell's article \"Gender and Cultural Analytics: Finding or Making Stereotypes?\" discusses the potential for gender and cultural biases to be perpetuated through the use of data analysis in the humanities. Mandell highlights the importance of recognizing the limitations of data analysis and the need for critical interpretation of the results.\n",
    "\n",
    "Mandell argues that while \"big data\" analysis can be useful in identifying patterns and trends, it can also reinforce existing stereotypes and biases. She suggests that \"data has an ideological and cultural history that can shape our expectations for what we will find and how we will interpret it\" (p. 156).\n",
    "\n",
    "Furthermore, Mandell argues that gender and cultural biases can be embedded in the algorithms used for data analysis. She notes that \"if we are not careful, we may be simply reproducing stereotypes and hierarchies that have been embedded in our data\" (p. 158).\n",
    "\n",
    "Mandell emphasizes the importance of critical interpretation and contextualization when using data analysis in the humanities. She suggests that \"we need to be constantly asking ourselves: what do we assume when we use these tools? What are the limitations of the data? What is the cultural and ideological context in which we are working?\" (p. 158).\n",
    "\n",
    "Overall, Mandell's article highlights the need for caution and critical reflection when using data analysis in the humanities, particularly in relation to gender and cultural biases. She suggests that we must be aware of the limitations and potential biases of our data and algorithms, and approach our analysis with a critical and contextualized perspective.\n",
    "\n",
    "One relevant quote from the text is: \"we need to be vigilant about the ways in which data analysis can reinforce stereotypes and hierarchies, and we need to be willing to question the data and the methods we use to analyze it\" (p. 159).\n",
    "\n",
    "##### Notes\n",
    "\n",
    "* Denaturalize gender categories, \n",
    "* google n-grams viewer identification of 'female language'\n",
    "* We overread 'the naturalization' of gender\n",
    "* Production of gender as a textual artifact\n",
    "* Construction of gender and its performance\n",
    "* The end 'the gender signal' to inform research questions that involve studying gender\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bit by Bit: Social Research in the Digital Age\n",
    "*Salganik, Matthew*\n",
    "\n",
    "Matthew Salganik's \"Bit by Bit: Social Research in the Digital Age\" is a book that explores the impact of new digital technologies on social research. Chapter 1, \"Introduction\", provides an overview of the key themes of the book and introduces the reader to the main concepts and ideas.\n",
    "\n",
    "Salganik argues that \"the digital age has created a new research landscape, one that requires new ways of thinking about how to conduct social research\" (p. 3). He suggests that digital technologies have opened up new opportunities for social researchers, but also pose new challenges.\n",
    "\n",
    "One of the key themes of the book is the concept of \"big data\". Salganik notes that \"big data is a new and exciting phenomenon, one that has the potential to transform social research\" (p. 6). However, he also cautions that big data is not a panacea, and that it comes with its own set of limitations and challenges.\n",
    "\n",
    "Another important theme of the book is the concept of \"social research 2.0\". Salganik suggests that social research 2.0 involves \"a shift in the way that social research is conducted, from a traditional, top-down approach to a more collaborative and participatory approach\" (p. 8). He argues that digital technologies have enabled researchers to engage with participants in new and innovative ways, and that this has the potential to revolutionize social research.\n",
    "\n",
    "Finally, Salganik emphasizes the importance of ethics and privacy in the digital age. He notes that \"as social researchers, we have a responsibility to protect the privacy and confidentiality of our participants\" (p. 11). He suggests that new digital technologies have created new challenges in this regard, and that researchers need to be proactive in addressing these challenges.\n",
    "\n",
    "Overall, Chapter 1 provides an introduction to the key themes of Salganik's book, and sets the stage for a broader discussion of the impact of digital technologies on social research. Salganik emphasizes the opportunities and challenges presented by new digital technologies, and highlights the importance of ethics and privacy in the digital age.\n",
    "\n",
    "One relevant quote from the text is: \"the digital age has created a new research landscape, one that requires new ways of thinking about how to conduct social research\" (p. 3).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChapterTwo: On Rational, Scientific, Objective Viewpoints from Mythical, Imaginary, Impossible Standpoints.\n",
    "*Catherine D’Ignazio and Lauren Klein*\n",
    "\n",
    "In \"Chapter Two: On Rational, Scientific, Objective Viewpoints from Mythical, Imaginary, Impossible Standpoints,\" Catherine D'Ignazio and Lauren Klein critique the notion of objectivity in data science, arguing that it is impossible to fully remove subjectivity from data collection and analysis. They suggest that acknowledging and embracing subjectivity can lead to more inclusive and equitable data practices.\n",
    "\n",
    "One quote that encapsulates their argument is: \"The belief in a purely rational, purely objective science has been a hallmark of modern Western thought. It is also a hallmark of the field of data science. But the idea that science is an objective, rational enterprise is a myth.\"\n",
    "\n",
    "D'Ignazio and Klein also suggest that embracing subjectivity can lead to more imaginative and creative data analysis: \"When we acknowledge that we bring ourselves to our data work, we also make space for imagination and creativity in how we approach that work. We can move beyond seeing our role as data scientists as simply cleaning and curating data, or writing and testing models, and instead view it as a fundamentally imaginative and creative endeavor.\"\n",
    "\n",
    "Ultimately, they argue that embracing subjectivity and diverse perspectives is necessary for ethical and equitable data practices: \"Ultimately, we argue that a more equitable data science must be one that acknowledges the messy, complex, and diverse realities of the world that data seeks to represent.\"\n",
    "\n",
    "##### Notes\n",
    "* the emotions and people behind the data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### “Seven Ways Humanists are Using Computers to Understand Text.” The Stone and the Shell\n",
    "*Ted Underwood*\n",
    "\n",
    "In his article “Seven Ways Humanists are Using Computers to Understand Text,” Ted Underwood explores how digital tools and techniques are being used in the field of humanities to analyze and understand large quantities of text. Underwood argues that these methods are not only useful for improving our understanding of literature and culture, but also for challenging our assumptions about how language and meaning work.\n",
    "\n",
    "The first method Underwood discusses is the use of topic modeling, a statistical technique that identifies patterns and clusters of words within a corpus of text. Underwood explains that this method can be used to explore the frequency of certain topics or themes within a corpus, as well as to identify previously unknown connections between texts. As he puts it, “The most exciting thing about topic modeling is not the topics themselves, but the ability to use them as lenses on cultural history.”\n",
    "\n",
    "The second method discussed by Underwood is sentiment analysis, which involves using algorithms to analyze the tone and mood of a text. This technique can be used to track changes in attitudes or emotions over time, and has been used to analyze everything from political speeches to popular music lyrics. As Underwood notes, “Sentiment analysis is not a substitute for human interpretation, but it can be an important tool for confirming or challenging our intuitive sense of a text.”\n",
    "\n",
    "The third method discussed by Underwood is network analysis, which involves mapping the connections and relationships between texts and authors. This technique can be used to explore literary influences and collaborations, as well as to identify previously unknown connections between texts. As Underwood puts it, “Network analysis can reveal the patterns of collaboration and influence that are often obscured by the way we traditionally study literary history.”\n",
    "\n",
    "The fourth method discussed by Underwood is named entity recognition, which involves using algorithms to identify and categorize named entities (such as people, places, and organizations) within a corpus of text. This technique can be used to track the popularity of certain names or topics over time, as well as to explore patterns of representation and bias within texts. As Underwood explains, “By using named entity recognition, we can identify not only the most common topics in a corpus, but also the individuals and organizations that are most frequently discussed.”\n",
    "\n",
    "The fifth method discussed by Underwood is distant reading, which involves analyzing large quantities of text in order to identify patterns and trends that may not be immediately visible to the human eye. As Underwood notes, “Distant reading can help us to understand the broad contours of literary history, and to identify patterns and trends that might not be visible at the level of individual texts.”\n",
    "\n",
    "The sixth method discussed by Underwood is stylometry, which involves analyzing the style and language of a text in order to identify the authorship or origin of a text. This technique has been used to identify previously unknown works by famous authors, as well as to explore the stylistic evolution of individual authors over time. As Underwood puts it, “Stylometry is not a substitute for close reading, but it can be an important tool for identifying the patterns and styles that make individual authors unique.”\n",
    "\n",
    "The seventh and final method discussed by Underwood is topic modeling in translation, which involves using topic modeling to explore patterns and themes within translated texts. This technique has been used to explore the challenges and opportunities of translating literature between different languages and cultures. As Underwood explains, “Topic modeling in translation can help us to better understand the complex ways in which language and culture intersect.”\n",
    "\n",
    "Throughout his article, Underwood emphasizes the importance of combining digital methods with traditional humanistic approaches in order to fully understand the complexities of language and meaning. As he notes, “Digital methods can help us to see new patterns and connections within texts, but they are not a substitute for the humanistic interpretation that remains at the heart of our work.”\n",
    "\n",
    "Overall, Underwood's article provides a comprehensive overview"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
