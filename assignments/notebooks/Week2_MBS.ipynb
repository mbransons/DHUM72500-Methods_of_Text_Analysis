{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmrhody/femethodsS23/blob/main/Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdt0sPtZxrO7"
      },
      "source": [
        "# Week 2: Getting Started with Jupyter and Google Collaboratory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vp-hSaixrO-"
      },
      "source": [
        "* Student Name: Michael Branson Smith\n",
        "* Date: 01/30/2023\n",
        "* Instructor: Lisa Rhody\n",
        "* Assignment due: 2/6/2023\n",
        "* Methods of Text Analysis\n",
        "* MA in DH at The Graduate Center, CUNY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV3brh3jxrO-"
      },
      "source": [
        "Click in the following cell and then click on the \"play\" icon to run it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n_HIFVEgxrO-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1 + 5 * 2 - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "IeujceYExrPA"
      },
      "source": [
        "If the code is running correctly, a green check mark will appear to the left of the []. Inside the [] a number will appear. This number represents the \"process number\"--which is to say the order in which the code you executed was executed within the notebook. Also, you will see the result of the math equation below the cell where the equation is. The answer should be 8. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS7YUloQFJBe"
      },
      "source": [
        "# Adding a Markdown / Text cell\n",
        "\n",
        "At the top of your notebook and just under the menu (the list of words that begin File, Edit, View, etc...), there should be two actions you can perform. One is \"+ Code\" and the other is \"+ Text.\" These will allow you to add either a code cell or a text cell in the area beneath whichever cell is currently active. \n",
        "\n",
        "For your next trick, click on this cell to make it \"active.\" Then move your cursor to the top of the page and click the \"+Text\" action. A new cell should open up. Click inside the new cell and type an answer to one of the following questions: \n",
        "\n",
        "* What is your favorite comfort food? \n",
        "* What is your favorite book? \n",
        "* Do you have a pet? If so, what kind? and what is its name? "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Family Pets\n",
        "We have three in my family (dog and two cats) and each pet has chosen my wife Amanda, my son Wyatt, or my daughter Bea as their number one. Somehow I'm every pet's number two, so that works!\n",
        "\n",
        "* Lucy – our black cat that is cuddly and the smart one in the family. She's Wyatt's.\n",
        "\n",
        "![Lucy the Black Cat](https://mbs.nyc/pets/lucy.jpg)\n",
        "\n",
        "* Lacey – our very sweet and nervous dog. She is 100% Amanda's! I'm a distant second.\n",
        "\n",
        "![Lacey the Nervous Puppy](https://mbs.nyc/pets/lacey.jpg)\n",
        "\n",
        "* Larry – our very fat and not the sharpest-knife-in-the-drawer cat. Bea's by blanket smoothering technique.\n",
        "\n",
        "![Larry the Fat Cat](https://mbs.nyc/pets/larry.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SUYTGC3GDS0"
      },
      "source": [
        "# Importing NLTK and text functions\n",
        "\n",
        "Next, click in the cell below. This cell will tell the notebook to pull into its working memory a library called NLTK (the Natural Language Toolkit) which is something we will use quite a lot this semester. It will also download the book corpora. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "y3VxE8S1xrPA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk \n",
        "nltk.download(\"book\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfhYAJPlGg3o"
      },
      "source": [
        "If this cell has executed properly, it will have lots of rows that begin [nltk_data] and at the end say \"True.\" We're not going to use much of NLTK this week, but it's helpful to practice because we'll need to do this a lot in the future. Please create a new text cell below. \n",
        "\n",
        "**EXERCISE**: If you had any problems, please explain. If not, just say \"All good.\" "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SWEET! ALL GOOD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMgYoXntxrPB"
      },
      "source": [
        "Finally, we're just going to play around with what we installed a little bit to make sure it's working for you. No worries if you have trouble with it... that's why we're doing this. Just to practice. \n",
        "\n",
        "**EXERCISE Part 1**: First, run the cell below. This is a sentence taken from the following article: Fabricant, Florence. “Porcini Mushrooms for Those With Fungi on the Brain.” The New York Times, 30 Jan. 2023. NYTimes.com, https://www.nytimes.com/2023/01/30/dining/mushrooms-porcini-italian.html.\n",
        "\n",
        "The output should include 2 rows. The first row will cut the text up into units called \"tokens.\" The second row will tag each word with a label for the part of speech. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LOsAFnBCxrPB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'purpose', 'of', 'the', 'experiment', 'is', 'to', 'throw', 'emissaries', 'into', 'time', ',', 'to', 'call', 'past', 'and', 'future', 'to', 'the', 'rescue', 'of', 'the', 'present', '.']\n",
            "[('The', 'DT'), ('purpose', 'NN'), ('of', 'IN'), ('the', 'DT'), ('experiment', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('throw', 'VB'), ('emissaries', 'NNS'), ('into', 'IN'), ('time', 'NN'), (',', ','), ('to', 'TO'), ('call', 'VB'), ('past', 'NN'), ('and', 'CC'), ('future', 'NN'), ('to', 'TO'), ('the', 'DT'), ('rescue', 'NN'), ('of', 'IN'), ('the', 'DT'), ('present', 'JJ'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"\"\"The purpose of the experiment is to throw emissaries into time, to call past and future to the rescue of the present.\"\"\"\n",
        "\n",
        "# nltk tokenization splitting into a list of words and punctuation symbols and quotation marks.\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "# part of speech tagger takes a list returns a list of tuples with two strings - the word and the part of speech\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "print(tagged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Hx7KhxIIuU"
      },
      "source": [
        "**EXERCISE Part Two** Click into the code cell above and replace the sentence beginning with Porcini all the way to the word purveyors with your own sentence or two. Be sure to leave in all 3 sets of quotation marks. Then run the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRQv5b78xrPB"
      },
      "source": [
        "# Congratulations!!! You've completed your first assignment. \n",
        "\n",
        "Click File, and in the drop down menu, select \"Save.\" Make sure that your notebook file saves in a folder that is shared with my gmail address: lisarhody.gc@gmail.com. \n",
        "\n",
        "If you are someone who would like to push further, You could get started with the NLTK Book Chapter 1 here: https://www.nltk.org/book/ch01.html. You can create a new notebook to track your work and submit that the same way. If you do, please save the notebook with the same naming strategy: lastname-week.ipynb. \n",
        "\n",
        "Congratulations! You're well on your way!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "bffae61b4a647f5c3a2b9689cc2bbc523f2c1227093a073b0d809d31c71c3583"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
