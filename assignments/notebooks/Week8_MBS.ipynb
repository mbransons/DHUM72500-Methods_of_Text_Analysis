{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmrhody/femethodsS23/blob/main/Week8_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAkti4G4I1dy"
      },
      "source": [
        "# Week 8: Working with Text Data from APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbVLjq4pI1d0"
      },
      "source": [
        "Fill out the cell below with your information. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kdnDlnxFI1d0"
      },
      "source": [
        "* Student Name: Michael Smith  \n",
        "* Date: 4/16/2023\n",
        "* Instructor: Lisa Rhody\n",
        "* Assignment due: \n",
        "* Methods of Text Analysis\n",
        "* MA in DH at The Graduate Center, CUNY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncgW8rT_I1d0"
      },
      "source": [
        "## Objectives\n",
        "This week you'll be working with the availablility of APIs and the data they provide, as well as learing about some of the steps that you need to take while cleaning and preparing text data for analysis. \n",
        "\n",
        "In this notebook, you will:\n",
        "* ingest data into a notebook from an API; \n",
        "* use Pandas dataframes to find and organize data; \n",
        "* uncover some of the challenges of working with data, including variation, multiple words with similar word stems, words with similar meanings, stopword control, and more; \n",
        "* Consider the relationship between the data you are working with, the forms of \"data cleaning\" or \"data scrubbing\" that most text analysis piplines use, and the challenges that those methods present a feminist critical approach. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egrAMMlOMIBS"
      },
      "source": [
        "# Getting Started\n",
        "As always, we need to begin by importing Python libraries that we know we will need to use. By this point, perhaps you are already familiar with some of them and know why we use them. Others may be less familiar to you. See if you can read through the list of imports and identify what each package does and why we will need it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yC6MGOIjJo9s"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOMkI2ZhI1d9"
      },
      "source": [
        "## Access data using an API\n",
        "In the following exercise, you will import data from the Chronicling America API. You will set parameters for what content and keywords to pull in, then you will send the request to the server. After you import the data, you'll organize and clean up the JSON format--in other words, when you get your search results, it will come packaged in a file format, called JSON. We will ingest the JSON file, turn it into a dictionary, and then turn part of that dictionary into a Pandas Dataframe. All we're doing when we turn text data into a dataframe is organizing the metadata and the files into a format that can be used and acted upon in order to do other kinds of analysis. \n",
        "\n",
        "To work with APIs, we will need to import a new library called \"[requests](https://pypi.org/project/requests/).\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m0GeV5aCI1d9"
      },
      "outputs": [],
      "source": [
        "# Make the Requests module available\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqz2XQ5NvmMD"
      },
      "source": [
        "# What are APIs? \n",
        "APIs are a set of routines that allow you to build from and interact with a software application. APIs make it possible for 2 software programs to work with each other. We will use APIs to pull data from applications. Many applications, like Twitter, Instagram, LinkedIn, and other applications have APIs. \n",
        "\n",
        "In the following example, you are going to use the requests library to make an http request to the [Open Movie Database](https://www.omdbapi.com/) (OMDb). We are going to use a security protocol called an API Key and request that the API return results to a query about the movie *The Princess Bride*. \n",
        "\n",
        "First, go to the API Key generator on the [OMDb website](https://www.omdbapi.com/apikey.aspx?__EVENTTARGET=freeAcct&__EVENTARGUMENT=&__LASTFOCUS=&__VIEWSTATE=%2FwEPDwUKLTIwNDY4MTIzNQ9kFgYCAQ9kFgICBw8WAh4HVmlzaWJsZWhkAgIPFgIfAGhkAgMPFgIfAGhkGAEFHl9fQ29udHJvbHNSZXF1aXJlUG9zdEJhY2tLZXlfXxYDBQtwYXRyZW9uQWNjdAUIZnJlZUFjY3QFCGZyZWVBY2N0oCxKYG7xaZwy2ktIrVmWGdWzxj%2FDhHQaAqqFYTiRTDE%3D&__VIEWSTATEGENERATOR=5E550F58&__EVENTVALIDATION=%2FwEdAAU%2BO86JjTqdg0yhuGR2tBukmSzhXfnlWWVdWIamVouVTzfZJuQDpLVS6HZFWq5fYpioiDjxFjSdCQfbG0SWduXFd8BcWGH1ot0k0SO7CfuulHLL4j%2B3qCcW3ReXhfb4KKsSs3zlQ%2B48KY6Qzm7wzZbR&at=freeAcct&Email=). Click the radio button next to FREE. Enter your email address, first, and last name, and then in the \"use\" section, you can write: \"Completing an assignment for class.\" Then click Submit. It usually takes just a few moments for a confirmation email to arrive in your email box. Be sure to click on the second link in the email first to validate your key. The email will include a sequence of characters and numbers that you will use in this exercise. Once you have set up a key, you can begin the rest of the activity. \n",
        "\n",
        "In order to retrieve data from the OMDb API using your API Key, we need to make a request using a communication protocol that is common on the internet: http. Essentially, what we will do is create a variable called `url` in which we will store an http request that is sent to the internet address www.omdbapi.com/. What follows the address, beginning with a question mark, is a query string. Query strings are not part of the URL syntax, but it tells the API (in this case) what your key is,and then what information you would like to retrieve. In this case, the information is all the information included in the record with the title *The Princess Bride*. \n",
        "\n",
        "Notice that the URL cannot contain spaces. Therefore, we insert the percent sign `%` where a space in the title might go. Alternately, we could put a + sign between each word. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Np8o-USEwFj5"
      },
      "outputs": [],
      "source": [
        "url = 'http://www.omdbapi.com/?apikey=4603ce48&t=the%princess%bride'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c9vnrqww3G3-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "requests.models.Response"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a variable movies and use the get method in requests to read in the \n",
        "# response from the URL.\n",
        "movies = requests.get(url)\n",
        "# What datatype is the variable movies?\n",
        "type(movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U-CoW7W3yjl"
      },
      "source": [
        "The result of the `requests.get()` method is specific to the requests library. In order to use the file, though, we need to convert the data from its current format into a JSON file. We do that by taking movies and applying the `.json' function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wnXRQHQD3qUQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take movies and turn it into json. \n",
        "json_data = movies.json()\n",
        "type(json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ouHxqvV4iB9"
      },
      "source": [
        "When you check the data type now, you will discover that the json file is saved as a dictionary, which is to say a series of \"keys\" and \"values\" saved in pairs. \n",
        "\n",
        "Finally, we need to create a for loop so that we can go through the API results and print out the keys and their associated values. So, for every key and it's associated value in the json_data object, we look at each item in the dictionary and print the key, then a : and then the associated values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "165Kh2la4gCX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: The Princess Bride\n",
            "Year: 1987\n",
            "Rated: PG\n",
            "Released: 09 Oct 1987\n",
            "Runtime: 98 min\n",
            "Genre: Adventure, Comedy, Family\n",
            "Director: Rob Reiner\n",
            "Writer: William Goldman\n",
            "Actors: Cary Elwes, Mandy Patinkin, Robin Wright\n",
            "Plot: A bedridden boy's grandfather reads him the story of a farmboy-turned-pirate who encounters numerous obstacles, enemies and allies in his quest to be reunited with his true love.\n",
            "Language: English\n",
            "Country: United States\n",
            "Awards: Nominated for 1 Oscar. 7 wins & 10 nominations total\n",
            "Poster: https://m.media-amazon.com/images/M/MV5BYzdiOTVjZmQtNjAyNy00YjA2LTk5ZTAtNmJkMGQ5N2RmNjUxXkEyXkFqcGdeQXVyMjUzOTY1NTc@._V1_SX300.jpg\n",
            "Ratings: [{'Source': 'Internet Movie Database', 'Value': '8.0/10'}, {'Source': 'Rotten Tomatoes', 'Value': '97%'}, {'Source': 'Metacritic', 'Value': '77/100'}]\n",
            "Metascore: 77\n",
            "imdbRating: 8.0\n",
            "imdbVotes: 433,206\n",
            "imdbID: tt0093779\n",
            "Type: movie\n",
            "DVD: 18 Jul 2000\n",
            "BoxOffice: $30,857,814\n",
            "Production: N/A\n",
            "Website: N/A\n",
            "Response: True\n"
          ]
        }
      ],
      "source": [
        "for key, value in json_data.items():\n",
        "  print(key + ':', value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qliewevs5UQZ"
      },
      "source": [
        "We know that we can search by title in the API because of the documentation on the [OMDb website](https://www.omdbapi.com/). Look under Usage and Parameters. In fact, the OMDb site includes examples, so that you can do a search and find the query string you need to get the result you are looking for. All the search parameters are listed here. \n",
        "\n",
        "Another way to search for a particular movie is with its item ID in the IMDB database. You can find the item identifier by looking at the end of the URL when you search for a movie. For example, in this URL https://www.imdb.com/title/tt2906216/ we would use the item ID `tt2906216`. There are also additional arguments that can be used in the query string for OMDb to find the full plot description. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dd-M2WyF5QNh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Dungeons & Dragons: Honor Among Thieves\n",
            "Year: 2023\n",
            "Rated: PG-13\n",
            "Released: 31 Mar 2023\n",
            "Runtime: 134 min\n",
            "Genre: Action, Adventure, Fantasy\n",
            "Director: John Francis Daley, Jonathan Goldstein\n",
            "Writer: Jonathan Goldstein, John Francis Daley, Michael Gilio\n",
            "Actors: Chris Pine, Michelle Rodriguez, Regé-Jean Page\n",
            "Plot: A charming thief and a band of unlikely adventurers embark on an epic quest to retrieve a lost relic, but things go dangerously awry when they run afoul of the wrong people.\n",
            "Language: English\n",
            "Country: United States, Canada, United Kingdom, Iceland, Australia\n",
            "Awards: 1 nomination\n",
            "Poster: https://m.media-amazon.com/images/M/MV5BZjAyMGMwYTEtNDk4ZS00YmY0LThhZjUtOWI4ZjFmZmU4N2I3XkEyXkFqcGdeQXVyMTEyNzQ1MTk0._V1_SX300.jpg\n",
            "Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.6/10'}, {'Source': 'Metacritic', 'Value': '71/100'}]\n",
            "Metascore: 71\n",
            "imdbRating: 7.6\n",
            "imdbVotes: 17,240\n",
            "imdbID: tt2906216\n",
            "Type: movie\n",
            "DVD: N/A\n",
            "BoxOffice: $38,500,000\n",
            "Production: Paramount Pictures\n",
            "Website: N/A\n",
            "Response: True\n"
          ]
        }
      ],
      "source": [
        "url = 'http://www.omdbapi.com/?apikey=4603ce48&i=tt2906216&plot=full'\n",
        "dandd = requests.get(url)\n",
        "json_data = dandd.json()\n",
        "for key, value in json_data.items():\n",
        "  print(key + ':', value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe84bMNwbXRc"
      },
      "source": [
        "# Chronicling America\n",
        "For this activity, we are going to use the [Chronicling America API](https://chroniclingamerica.loc.gov/about/api/), which is created and maintained by the Library of Congress. Chronicling America is an archive of digitized newspapers from across the United States that are not under copyright protection by another digitization vendor. It is part of the National Digitial Newspaper project funded by the National Endowment for the Humanities. There are more than [140,000 newspaper titles](https://chroniclingamerica.loc.gov/search/titles/) included in the collection. \n",
        "\n",
        "If you're interested in some of the critiques of the Chronicling America project, you might want to read Benjamin Fagen's article \"Chronicling White America.\" (Fagan, Benjamin. \"Chronicling White America.\" American Periodicals: A Journal of History & Criticism, vol. 26 no. 1, 2016, p. 10-13. Project MUSE https://muse.jhu.edu/article/613375.) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gTyHRrBcI1d9"
      },
      "outputs": [],
      "source": [
        "# Create a variable called 'api_search_url' and give it a value\n",
        "api_search_url = 'https://chroniclingamerica.loc.gov/search/pages/results/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ZQsPU7JnI1d9"
      },
      "outputs": [],
      "source": [
        "# This creates a dictionary called 'params' and sets values for the API's mandatory parameters\n",
        "# The parameters are drawn from the API documentation which describes the fields in the API. \n",
        "params = {\n",
        "    'proxtext': 'walrus' # Search for this keyword -- feel free to change!\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH9hFU3qI1d9"
      },
      "source": [
        "(Later on, you will be asked to return to the above cell and change the search parameters. You do this by replacing `poetry` with `yourterm`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YHzRgVgLI1d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'proxtext': 'walrus', 'format': 'json'}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The following line adds a value for 'encoding' to our dictionary\n",
        "params['format'] = 'json'\n",
        "\n",
        "# Let's view the updated dictionary\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "rtQtczZBI1d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's the formatted url that gets sent to the ChronAmerca API:\n",
            "https://chroniclingamerica.loc.gov/search/pages/results/?proxtext=walrus&format=json\n",
            "\n",
            "All ok\n"
          ]
        }
      ],
      "source": [
        "# The next line uses the requests package that we imported above to pull data from the Chronicling America API \n",
        "# and stores the result in a variable called 'response'\n",
        "response = requests.get(api_search_url, params=params)\n",
        "\n",
        "# We use a print statement to show us the url that we are sending to the API\n",
        "print('Here\\'s the formatted url that gets sent to the ChronAmerca API:\\n{}\\n'.format(response.url)) \n",
        "\n",
        "# It's nice to have some feedback about the status of the API response \n",
        "# to make sure there were no errors. The following checks to see that there are no errors and shows a response.\n",
        "if response.status_code == requests.codes.ok:\n",
        "    print('All ok')\n",
        "elif response.status_code == 403:\n",
        "    print('There was an authentication error. Did you paste your API above?')\n",
        "else:\n",
        "    print('There was a problem. Error code: {}'.format(response.status_code))\n",
        "    print('Try running this cell again.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0yrvvwuHI1d-"
      },
      "outputs": [],
      "source": [
        "# We are going to take the Chronicling America API's JSON results and turn them into a Python variable called 'data'\n",
        "data = response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn667lxtfHLu"
      },
      "source": [
        "The request that we made was for data formatted in JSON, which means Javascript Object Notation. JSON is a structured way of organizing information and it can be converted into a Python Dataframe; however, it's not always easy for a human to read. We're going to use another package called Prettify to use indentation and color to help make the JSON a little more understandable to the human reader. We're also using a json library and a library called Pygments to add some colour to the output. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "KgaMjeSJI1d-",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Let's prettify the raw JSON data and then display it.\n",
        "\n",
        "# We're using the Pygments library to add some colour to the output, so we need to import it\n",
        "import json\n",
        "from pygments import highlight, lexers, formatters\n",
        "import pprint\n",
        "\n",
        "# This uses Python's JSON module to output the results as nicely indented text\n",
        "formatted_data = json.dumps(data, indent=2)\n",
        "\n",
        "# This colours the text\n",
        "highlighted_data = highlight(formatted_data, lexers.JsonLexer(), formatters.TerminalFormatter())\n",
        "\n",
        "# And now display the results\n",
        "# print(highlighted_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "eamcN_jPotmb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0CdHJzSnsXp"
      },
      "source": [
        "## Reading text in a dataframe\n",
        "Next, you will use what we learned about the data in the API using the keys. We're going to look into the \"items\" entry in the JSON file and create a dataframe using Pandas that pulls out the title, content, and year of publication for each of the items. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "nQJJd7IAHKKA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drill down into the API data to find the filds we want to pull out and work with\n",
        "json_data = json.loads(formatted_data)\n",
        "# print(json_data['items'])\n",
        "cleaned_papers = []\n",
        "for item in json_data['items']:\n",
        "  # print(item['ocr_eng'])\n",
        "  cleaned_papers.append({'title': item['title'], 'content': item['ocr_eng'], 'date': item['date'], 'url': item['url'] })\n",
        "# print(cleaned_papers)\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "# pp.pprint(cleaned_papers)\n",
        "papers_df = pd.DataFrame(cleaned_papers)\n",
        "len(papers_df)\n",
        "# papers_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from string import punctuation\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", text) # Remove punctuation and special characters\n",
        "    text = \" \".join(text.split())  # Remove extra spaces, tabs, and new lines\n",
        "    return text\n",
        "\n",
        "papers_df[\"text_col\"] = papers_df['content'].apply(lambda t: preprocess_text(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>url</th>\n",
              "      <th>text_col</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The San Francisco call. [volume]</td>\n",
              "      <td>An Eskimo just back\\nfrom fishing\\nMeets compa...</td>\n",
              "      <td>19100227</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8506...</td>\n",
              "      <td>an eskimo just back from fishing meets company...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mining-dredging edition Nome daily nugget. [vo...</td>\n",
              "      <td>f..-----t\\n• •\\ni ?\\nONF. of tile most interes...</td>\n",
              "      <td>19151001</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/201827...</td>\n",
              "      <td>ft i onf of tile most interesting of tile dive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Washington times. [volume]</td>\n",
              "      <td>I' i I\\n■■ I* ■- ■\\ni BOOK OF MAGIC—Why Is Mr....</td>\n",
              "      <td>19230114</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>i i i i i book of magicwhy is mr walrus so sad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The times dispatch. [volume]</td>\n",
              "      <td>,*TKE TIMES-DISPATCHi RICHMOND, VA., SUNDAY, J...</td>\n",
              "      <td>19070922</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8503...</td>\n",
              "      <td>tke timesdispatchi richmond va sunday jglotemb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>ycu)^ jrrk s^lliiife Sttbutie.\\nVKEPAR ITIOXS ...</td>\n",
              "      <td>19031122</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>ycu jrrk slliiife sttbutie vkepar itioxs for t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>Heard and Se\\nParticular Mr. Walrus\\nBy MARY G...</td>\n",
              "      <td>19190601</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>heard and se particular mr walrus by mary grah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>GAMBELL\\nNEWS LETTER\\nBy CLARENCE IRRIGOO\\nFal...</td>\n",
              "      <td>19571225</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>gambell news letter by clarence irrigoo fall 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>BRINGING HOME THE ESQUIMAU BACON\\nHAVE you eve...</td>\n",
              "      <td>19211009</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>bringing home the esquimau bacon have you ever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>ANYBODY WANT A WALRUS HEAD TROPHY?\\nThe time h...</td>\n",
              "      <td>19561015</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>anybody want a walrus head trophy the time has...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Evening star. [volume]</td>\n",
              "      <td>% Bet she'd give her eye-teeth\\nfor what we've...</td>\n",
              "      <td>19440618</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
              "      <td>bet shed give her eyeteeth for what weve got 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Detroit evening times.</td>\n",
              "      <td>AT DAWN 'THE WALRUS’ COMES TO VAL AND SAYS. ‘T...</td>\n",
              "      <td>19440213</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8806...</td>\n",
              "      <td>at dawn the walrus comes to val and says theps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Evening star. [volume]</td>\n",
              "      <td>Horry GtQQM\\n■ ' • I » * iik\\nTOY IN ORBIT: Ki...</td>\n",
              "      <td>19611105</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
              "      <td>horry gtqqm i iik toy in orbit kimowhtan siloo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mining-dredging edition Nome daily nugget. [vo...</td>\n",
              "      <td>window, usually located in the roof\\ncovered w...</td>\n",
              "      <td>19151001</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/201827...</td>\n",
              "      <td>window usually located in the roof covered wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The Waterbury Democrat. [volume]</td>\n",
              "      <td>Walrus Is Most Maligned Plane\\nBut British Fle...</td>\n",
              "      <td>19430521</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8201...</td>\n",
              "      <td>walrus is most maligned plane but british flee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>THE NOME NUGGET\\nPublished Monday, Wednesday a...</td>\n",
              "      <td>19560709</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>the nome nugget published monday wednesday and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The Wrangell sentinel.</td>\n",
              "      <td>Reynolds Hunts Walrus\\n(Seattle Times)\\n&lt;fr.fr...</td>\n",
              "      <td>19380923</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn9405...</td>\n",
              "      <td>reynolds hunts walrus seattle times frfr48huju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>announcing Its proprietor's name. These are th...</td>\n",
              "      <td>18970829</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>announcing its proprietors name these are the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>1-- w—mm—mm\\nHUH\\n*1 .\\nSaturday, 9 a.m., N. C...</td>\n",
              "      <td>19550603</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>1 wmmmm huh 1 saturday 9 am n c store all kind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Mining-dredging edition Nome daily nugget. [vo...</td>\n",
              "      <td>Reviewing as a whole the possibilities of fish...</td>\n",
              "      <td>19161001</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/201827...</td>\n",
              "      <td>reviewing as a whole the possibilities of fish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>El Paso herald.</td>\n",
              "      <td>COMIC SECTION\\nEL PASO HERALD\\nApril 10 1915\\n...</td>\n",
              "      <td>19150410</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8808...</td>\n",
              "      <td>comic section el paso herald april 10 1915 cop...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "0                    The San Francisco call. [volume]   \n",
              "1   Mining-dredging edition Nome daily nugget. [vo...   \n",
              "2                      The Washington times. [volume]   \n",
              "3                        The times dispatch. [volume]   \n",
              "4                          New-York tribune. [volume]   \n",
              "5                          New-York tribune. [volume]   \n",
              "6                           The Nome nugget. [volume]   \n",
              "7                          New-York tribune. [volume]   \n",
              "8                           The Nome nugget. [volume]   \n",
              "9                              Evening star. [volume]   \n",
              "10                             Detroit evening times.   \n",
              "11                             Evening star. [volume]   \n",
              "12  Mining-dredging edition Nome daily nugget. [vo...   \n",
              "13                   The Waterbury Democrat. [volume]   \n",
              "14                          The Nome nugget. [volume]   \n",
              "15                             The Wrangell sentinel.   \n",
              "16                         New-York tribune. [volume]   \n",
              "17                          The Nome nugget. [volume]   \n",
              "18  Mining-dredging edition Nome daily nugget. [vo...   \n",
              "19                                    El Paso herald.   \n",
              "\n",
              "                                              content      date  \\\n",
              "0   An Eskimo just back\\nfrom fishing\\nMeets compa...  19100227   \n",
              "1   f..-----t\\n• •\\ni ?\\nONF. of tile most interes...  19151001   \n",
              "2   I' i I\\n■■ I* ■- ■\\ni BOOK OF MAGIC—Why Is Mr....  19230114   \n",
              "3   ,*TKE TIMES-DISPATCHi RICHMOND, VA., SUNDAY, J...  19070922   \n",
              "4   ycu)^ jrrk s^lliiife Sttbutie.\\nVKEPAR ITIOXS ...  19031122   \n",
              "5   Heard and Se\\nParticular Mr. Walrus\\nBy MARY G...  19190601   \n",
              "6   GAMBELL\\nNEWS LETTER\\nBy CLARENCE IRRIGOO\\nFal...  19571225   \n",
              "7   BRINGING HOME THE ESQUIMAU BACON\\nHAVE you eve...  19211009   \n",
              "8   ANYBODY WANT A WALRUS HEAD TROPHY?\\nThe time h...  19561015   \n",
              "9   % Bet she'd give her eye-teeth\\nfor what we've...  19440618   \n",
              "10  AT DAWN 'THE WALRUS’ COMES TO VAL AND SAYS. ‘T...  19440213   \n",
              "11  Horry GtQQM\\n■ ' • I » * iik\\nTOY IN ORBIT: Ki...  19611105   \n",
              "12  window, usually located in the roof\\ncovered w...  19151001   \n",
              "13  Walrus Is Most Maligned Plane\\nBut British Fle...  19430521   \n",
              "14  THE NOME NUGGET\\nPublished Monday, Wednesday a...  19560709   \n",
              "15  Reynolds Hunts Walrus\\n(Seattle Times)\\n<fr.fr...  19380923   \n",
              "16  announcing Its proprietor's name. These are th...  18970829   \n",
              "17  1-- w—mm—mm\\nHUH\\n*1 .\\nSaturday, 9 a.m., N. C...  19550603   \n",
              "18  Reviewing as a whole the possibilities of fish...  19161001   \n",
              "19  COMIC SECTION\\nEL PASO HERALD\\nApril 10 1915\\n...  19150410   \n",
              "\n",
              "                                                  url  \\\n",
              "0   https://chroniclingamerica.loc.gov/lccn/sn8506...   \n",
              "1   https://chroniclingamerica.loc.gov/lccn/201827...   \n",
              "2   https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "3   https://chroniclingamerica.loc.gov/lccn/sn8503...   \n",
              "4   https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "5   https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "6   https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "7   https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "8   https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "9   https://chroniclingamerica.loc.gov/lccn/sn8304...   \n",
              "10  https://chroniclingamerica.loc.gov/lccn/sn8806...   \n",
              "11  https://chroniclingamerica.loc.gov/lccn/sn8304...   \n",
              "12  https://chroniclingamerica.loc.gov/lccn/201827...   \n",
              "13  https://chroniclingamerica.loc.gov/lccn/sn8201...   \n",
              "14  https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "15  https://chroniclingamerica.loc.gov/lccn/sn9405...   \n",
              "16  https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "17  https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "18  https://chroniclingamerica.loc.gov/lccn/201827...   \n",
              "19  https://chroniclingamerica.loc.gov/lccn/sn8808...   \n",
              "\n",
              "                                             text_col  \n",
              "0   an eskimo just back from fishing meets company...  \n",
              "1   ft i onf of tile most interesting of tile dive...  \n",
              "2   i i i i i book of magicwhy is mr walrus so sad...  \n",
              "3   tke timesdispatchi richmond va sunday jglotemb...  \n",
              "4   ycu jrrk slliiife sttbutie vkepar itioxs for t...  \n",
              "5   heard and se particular mr walrus by mary grah...  \n",
              "6   gambell news letter by clarence irrigoo fall 1...  \n",
              "7   bringing home the esquimau bacon have you ever...  \n",
              "8   anybody want a walrus head trophy the time has...  \n",
              "9   bet shed give her eyeteeth for what weve got 1...  \n",
              "10  at dawn the walrus comes to val and says theps...  \n",
              "11  horry gtqqm i iik toy in orbit kimowhtan siloo...  \n",
              "12  window usually located in the roof covered wit...  \n",
              "13  walrus is most maligned plane but british flee...  \n",
              "14  the nome nugget published monday wednesday and...  \n",
              "15  reynolds hunts walrus seattle times frfr48huju...  \n",
              "16  announcing its proprietors name these are the ...  \n",
              "17  1 wmmmm huh 1 saturday 9 am n c store all kind...  \n",
              "18  reviewing as a whole the possibilities of fish...  \n",
              "19  comic section el paso herald april 10 1915 cop...  "
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "papers_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/michaelsmith/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "stopwords_ = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    clean_tokens = [t for t in tokens if not t in stopwords_]\n",
        "    return clean_tokens\n",
        "\n",
        "papers_df['words'] = papers_df['text_col'].apply(lambda t: tokenize_text(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>url</th>\n",
              "      <th>text_col</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The San Francisco call. [volume]</td>\n",
              "      <td>An Eskimo just back\\nfrom fishing\\nMeets compa...</td>\n",
              "      <td>19100227</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8506...</td>\n",
              "      <td>an eskimo just back from fishing meets company...</td>\n",
              "      <td>[eskimo, back, fishing, meets, company, hi, 3,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mining-dredging edition Nome daily nugget. [vo...</td>\n",
              "      <td>f..-----t\\n• •\\ni ?\\nONF. of tile most interes...</td>\n",
              "      <td>19151001</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/201827...</td>\n",
              "      <td>ft i onf of tile most interesting of tile dive...</td>\n",
              "      <td>[ft, onf, tile, interesting, tile, diverse, fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Washington times. [volume]</td>\n",
              "      <td>I' i I\\n■■ I* ■- ■\\ni BOOK OF MAGIC—Why Is Mr....</td>\n",
              "      <td>19230114</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>i i i i i book of magicwhy is mr walrus so sad...</td>\n",
              "      <td>[book, magicwhy, mr, walrus, sad, u, n, jl, mg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The times dispatch. [volume]</td>\n",
              "      <td>,*TKE TIMES-DISPATCHi RICHMOND, VA., SUNDAY, J...</td>\n",
              "      <td>19070922</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8503...</td>\n",
              "      <td>tke timesdispatchi richmond va sunday jglotemb...</td>\n",
              "      <td>[tke, timesdispatchi, richmond, va, sunday, jg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>ycu)^ jrrk s^lliiife Sttbutie.\\nVKEPAR ITIOXS ...</td>\n",
              "      <td>19031122</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>ycu jrrk slliiife sttbutie vkepar itioxs for t...</td>\n",
              "      <td>[ycu, jrrk, slliiife, sttbutie, vkepar, itioxs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>Heard and Se\\nParticular Mr. Walrus\\nBy MARY G...</td>\n",
              "      <td>19190601</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>heard and se particular mr walrus by mary grah...</td>\n",
              "      <td>[heard, se, particular, mr, walrus, mary, grah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>GAMBELL\\nNEWS LETTER\\nBy CLARENCE IRRIGOO\\nFal...</td>\n",
              "      <td>19571225</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>gambell news letter by clarence irrigoo fall 1...</td>\n",
              "      <td>[gambell, news, letter, clarence, irrigoo, fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>BRINGING HOME THE ESQUIMAU BACON\\nHAVE you eve...</td>\n",
              "      <td>19211009</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>bringing home the esquimau bacon have you ever...</td>\n",
              "      <td>[bringing, home, esquimau, bacon, ever, seen, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>ANYBODY WANT A WALRUS HEAD TROPHY?\\nThe time h...</td>\n",
              "      <td>19561015</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>anybody want a walrus head trophy the time has...</td>\n",
              "      <td>[anybody, want, walrus, head, trophy, time, co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Evening star. [volume]</td>\n",
              "      <td>% Bet she'd give her eye-teeth\\nfor what we've...</td>\n",
              "      <td>19440618</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
              "      <td>bet shed give her eyeteeth for what weve got 1...</td>\n",
              "      <td>[bet, shed, give, eyeteeth, weve, got, 1, cant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Detroit evening times.</td>\n",
              "      <td>AT DAWN 'THE WALRUS’ COMES TO VAL AND SAYS. ‘T...</td>\n",
              "      <td>19440213</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8806...</td>\n",
              "      <td>at dawn the walrus comes to val and says theps...</td>\n",
              "      <td>[dawn, walrus, comes, val, says, theps, val, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Evening star. [volume]</td>\n",
              "      <td>Horry GtQQM\\n■ ' • I » * iik\\nTOY IN ORBIT: Ki...</td>\n",
              "      <td>19611105</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
              "      <td>horry gtqqm i iik toy in orbit kimowhtan siloo...</td>\n",
              "      <td>[horry, gtqqm, iik, toy, orbit, kimowhtan, sil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mining-dredging edition Nome daily nugget. [vo...</td>\n",
              "      <td>window, usually located in the roof\\ncovered w...</td>\n",
              "      <td>19151001</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/201827...</td>\n",
              "      <td>window usually located in the roof covered wit...</td>\n",
              "      <td>[window, usually, located, roof, covered, oile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The Waterbury Democrat. [volume]</td>\n",
              "      <td>Walrus Is Most Maligned Plane\\nBut British Fle...</td>\n",
              "      <td>19430521</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8201...</td>\n",
              "      <td>walrus is most maligned plane but british flee...</td>\n",
              "      <td>[walrus, maligned, plane, british, fleet, swea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>THE NOME NUGGET\\nPublished Monday, Wednesday a...</td>\n",
              "      <td>19560709</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>the nome nugget published monday wednesday and...</td>\n",
              "      <td>[nome, nugget, published, monday, wednesday, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The Wrangell sentinel.</td>\n",
              "      <td>Reynolds Hunts Walrus\\n(Seattle Times)\\n&lt;fr.fr...</td>\n",
              "      <td>19380923</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn9405...</td>\n",
              "      <td>reynolds hunts walrus seattle times frfr48huju...</td>\n",
              "      <td>[reynolds, hunts, walrus, seattle, times, frfr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>New-York tribune. [volume]</td>\n",
              "      <td>announcing Its proprietor's name. These are th...</td>\n",
              "      <td>18970829</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>announcing its proprietors name these are the ...</td>\n",
              "      <td>[announcing, proprietors, name, afleos, oyster...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The Nome nugget. [volume]</td>\n",
              "      <td>1-- w—mm—mm\\nHUH\\n*1 .\\nSaturday, 9 a.m., N. C...</td>\n",
              "      <td>19550603</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8402...</td>\n",
              "      <td>1 wmmmm huh 1 saturday 9 am n c store all kind...</td>\n",
              "      <td>[1, wmmmm, huh, 1, saturday, 9, n, c, store, k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Mining-dredging edition Nome daily nugget. [vo...</td>\n",
              "      <td>Reviewing as a whole the possibilities of fish...</td>\n",
              "      <td>19161001</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/201827...</td>\n",
              "      <td>reviewing as a whole the possibilities of fish...</td>\n",
              "      <td>[reviewing, whole, possibilities, fishing, sec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>El Paso herald.</td>\n",
              "      <td>COMIC SECTION\\nEL PASO HERALD\\nApril 10 1915\\n...</td>\n",
              "      <td>19150410</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8808...</td>\n",
              "      <td>comic section el paso herald april 10 1915 cop...</td>\n",
              "      <td>[comic, section, el, paso, herald, april, 10, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "0                    The San Francisco call. [volume]   \n",
              "1   Mining-dredging edition Nome daily nugget. [vo...   \n",
              "2                      The Washington times. [volume]   \n",
              "3                        The times dispatch. [volume]   \n",
              "4                          New-York tribune. [volume]   \n",
              "5                          New-York tribune. [volume]   \n",
              "6                           The Nome nugget. [volume]   \n",
              "7                          New-York tribune. [volume]   \n",
              "8                           The Nome nugget. [volume]   \n",
              "9                              Evening star. [volume]   \n",
              "10                             Detroit evening times.   \n",
              "11                             Evening star. [volume]   \n",
              "12  Mining-dredging edition Nome daily nugget. [vo...   \n",
              "13                   The Waterbury Democrat. [volume]   \n",
              "14                          The Nome nugget. [volume]   \n",
              "15                             The Wrangell sentinel.   \n",
              "16                         New-York tribune. [volume]   \n",
              "17                          The Nome nugget. [volume]   \n",
              "18  Mining-dredging edition Nome daily nugget. [vo...   \n",
              "19                                    El Paso herald.   \n",
              "\n",
              "                                              content      date  \\\n",
              "0   An Eskimo just back\\nfrom fishing\\nMeets compa...  19100227   \n",
              "1   f..-----t\\n• •\\ni ?\\nONF. of tile most interes...  19151001   \n",
              "2   I' i I\\n■■ I* ■- ■\\ni BOOK OF MAGIC—Why Is Mr....  19230114   \n",
              "3   ,*TKE TIMES-DISPATCHi RICHMOND, VA., SUNDAY, J...  19070922   \n",
              "4   ycu)^ jrrk s^lliiife Sttbutie.\\nVKEPAR ITIOXS ...  19031122   \n",
              "5   Heard and Se\\nParticular Mr. Walrus\\nBy MARY G...  19190601   \n",
              "6   GAMBELL\\nNEWS LETTER\\nBy CLARENCE IRRIGOO\\nFal...  19571225   \n",
              "7   BRINGING HOME THE ESQUIMAU BACON\\nHAVE you eve...  19211009   \n",
              "8   ANYBODY WANT A WALRUS HEAD TROPHY?\\nThe time h...  19561015   \n",
              "9   % Bet she'd give her eye-teeth\\nfor what we've...  19440618   \n",
              "10  AT DAWN 'THE WALRUS’ COMES TO VAL AND SAYS. ‘T...  19440213   \n",
              "11  Horry GtQQM\\n■ ' • I » * iik\\nTOY IN ORBIT: Ki...  19611105   \n",
              "12  window, usually located in the roof\\ncovered w...  19151001   \n",
              "13  Walrus Is Most Maligned Plane\\nBut British Fle...  19430521   \n",
              "14  THE NOME NUGGET\\nPublished Monday, Wednesday a...  19560709   \n",
              "15  Reynolds Hunts Walrus\\n(Seattle Times)\\n<fr.fr...  19380923   \n",
              "16  announcing Its proprietor's name. These are th...  18970829   \n",
              "17  1-- w—mm—mm\\nHUH\\n*1 .\\nSaturday, 9 a.m., N. C...  19550603   \n",
              "18  Reviewing as a whole the possibilities of fish...  19161001   \n",
              "19  COMIC SECTION\\nEL PASO HERALD\\nApril 10 1915\\n...  19150410   \n",
              "\n",
              "                                                  url  \\\n",
              "0   https://chroniclingamerica.loc.gov/lccn/sn8506...   \n",
              "1   https://chroniclingamerica.loc.gov/lccn/201827...   \n",
              "2   https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "3   https://chroniclingamerica.loc.gov/lccn/sn8503...   \n",
              "4   https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "5   https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "6   https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "7   https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "8   https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "9   https://chroniclingamerica.loc.gov/lccn/sn8304...   \n",
              "10  https://chroniclingamerica.loc.gov/lccn/sn8806...   \n",
              "11  https://chroniclingamerica.loc.gov/lccn/sn8304...   \n",
              "12  https://chroniclingamerica.loc.gov/lccn/201827...   \n",
              "13  https://chroniclingamerica.loc.gov/lccn/sn8201...   \n",
              "14  https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "15  https://chroniclingamerica.loc.gov/lccn/sn9405...   \n",
              "16  https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "17  https://chroniclingamerica.loc.gov/lccn/sn8402...   \n",
              "18  https://chroniclingamerica.loc.gov/lccn/201827...   \n",
              "19  https://chroniclingamerica.loc.gov/lccn/sn8808...   \n",
              "\n",
              "                                             text_col  \\\n",
              "0   an eskimo just back from fishing meets company...   \n",
              "1   ft i onf of tile most interesting of tile dive...   \n",
              "2   i i i i i book of magicwhy is mr walrus so sad...   \n",
              "3   tke timesdispatchi richmond va sunday jglotemb...   \n",
              "4   ycu jrrk slliiife sttbutie vkepar itioxs for t...   \n",
              "5   heard and se particular mr walrus by mary grah...   \n",
              "6   gambell news letter by clarence irrigoo fall 1...   \n",
              "7   bringing home the esquimau bacon have you ever...   \n",
              "8   anybody want a walrus head trophy the time has...   \n",
              "9   bet shed give her eyeteeth for what weve got 1...   \n",
              "10  at dawn the walrus comes to val and says theps...   \n",
              "11  horry gtqqm i iik toy in orbit kimowhtan siloo...   \n",
              "12  window usually located in the roof covered wit...   \n",
              "13  walrus is most maligned plane but british flee...   \n",
              "14  the nome nugget published monday wednesday and...   \n",
              "15  reynolds hunts walrus seattle times frfr48huju...   \n",
              "16  announcing its proprietors name these are the ...   \n",
              "17  1 wmmmm huh 1 saturday 9 am n c store all kind...   \n",
              "18  reviewing as a whole the possibilities of fish...   \n",
              "19  comic section el paso herald april 10 1915 cop...   \n",
              "\n",
              "                                                words  \n",
              "0   [eskimo, back, fishing, meets, company, hi, 3,...  \n",
              "1   [ft, onf, tile, interesting, tile, diverse, fo...  \n",
              "2   [book, magicwhy, mr, walrus, sad, u, n, jl, mg...  \n",
              "3   [tke, timesdispatchi, richmond, va, sunday, jg...  \n",
              "4   [ycu, jrrk, slliiife, sttbutie, vkepar, itioxs...  \n",
              "5   [heard, se, particular, mr, walrus, mary, grah...  \n",
              "6   [gambell, news, letter, clarence, irrigoo, fal...  \n",
              "7   [bringing, home, esquimau, bacon, ever, seen, ...  \n",
              "8   [anybody, want, walrus, head, trophy, time, co...  \n",
              "9   [bet, shed, give, eyeteeth, weve, got, 1, cant...  \n",
              "10  [dawn, walrus, comes, val, says, theps, val, a...  \n",
              "11  [horry, gtqqm, iik, toy, orbit, kimowhtan, sil...  \n",
              "12  [window, usually, located, roof, covered, oile...  \n",
              "13  [walrus, maligned, plane, british, fleet, swea...  \n",
              "14  [nome, nugget, published, monday, wednesday, f...  \n",
              "15  [reynolds, hunts, walrus, seattle, times, frfr...  \n",
              "16  [announcing, proprietors, name, afleos, oyster...  \n",
              "17  [1, wmmmm, huh, 1, saturday, 9, n, c, store, k...  \n",
              "18  [reviewing, whole, possibilities, fishing, sec...  \n",
              "19  [comic, section, el, paso, herald, april, 10, ...  "
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "papers_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0frc3IayI1d-"
      },
      "source": [
        "The output of the above cell will be quite long. Before turning in this assignment, please delete the cell above so the file you turn in is not difficult to read. Thank you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "vUsS7enaI1d-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(cleaned_papers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZCdbRWkI1d-"
      },
      "source": [
        "In the cell below, we will take the nested dictionary, which is also a json format, and we will convert it into a DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "rqD_1IlQI1d-"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>totalItems</th>\n",
              "      <th>endIndex</th>\n",
              "      <th>startIndex</th>\n",
              "      <th>itemsPerPage</th>\n",
              "      <th>items</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 25, 'county': ['New York'], 'edit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 131, 'county': [None], 'edition':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 7, 'county': ['Fulton'], 'edition...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 15, 'county': ['Prince George's']...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 17, 'county': ['Cook County'], 'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 13, 'county': ['Cook County'], 'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 9, 'county': ['Cook County'], 'ed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 3, 'county': ['Cook County'], 'ed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 1, 'county': ['Fayette', 'Hamilto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 93, 'county': [None], 'edition': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 24, 'county': ['Cook County'], 'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 3, 'county': ['Lancaster'], 'edit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 41, 'county': [None], 'edition': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 42, 'county': [None], 'edition': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 40, 'county': [None], 'edition': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 9, 'county': ['Hennepin', 'Ramsey...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 154, 'county': [None], 'edition':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 36, 'county': ['Cascade'], 'editi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 18, 'county': ['Douglas'], 'editi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>519976</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>{'sequence': 30, 'county': ['Cook County'], 'e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    totalItems  endIndex  startIndex  itemsPerPage  \\\n",
              "0       519976        20           1            20   \n",
              "1       519976        20           1            20   \n",
              "2       519976        20           1            20   \n",
              "3       519976        20           1            20   \n",
              "4       519976        20           1            20   \n",
              "5       519976        20           1            20   \n",
              "6       519976        20           1            20   \n",
              "7       519976        20           1            20   \n",
              "8       519976        20           1            20   \n",
              "9       519976        20           1            20   \n",
              "10      519976        20           1            20   \n",
              "11      519976        20           1            20   \n",
              "12      519976        20           1            20   \n",
              "13      519976        20           1            20   \n",
              "14      519976        20           1            20   \n",
              "15      519976        20           1            20   \n",
              "16      519976        20           1            20   \n",
              "17      519976        20           1            20   \n",
              "18      519976        20           1            20   \n",
              "19      519976        20           1            20   \n",
              "\n",
              "                                                items  \n",
              "0   {'sequence': 25, 'county': ['New York'], 'edit...  \n",
              "1   {'sequence': 131, 'county': [None], 'edition':...  \n",
              "2   {'sequence': 7, 'county': ['Fulton'], 'edition...  \n",
              "3   {'sequence': 15, 'county': ['Prince George's']...  \n",
              "4   {'sequence': 17, 'county': ['Cook County'], 'e...  \n",
              "5   {'sequence': 13, 'county': ['Cook County'], 'e...  \n",
              "6   {'sequence': 9, 'county': ['Cook County'], 'ed...  \n",
              "7   {'sequence': 3, 'county': ['Cook County'], 'ed...  \n",
              "8   {'sequence': 1, 'county': ['Fayette', 'Hamilto...  \n",
              "9   {'sequence': 93, 'county': [None], 'edition': ...  \n",
              "10  {'sequence': 24, 'county': ['Cook County'], 'e...  \n",
              "11  {'sequence': 3, 'county': ['Lancaster'], 'edit...  \n",
              "12  {'sequence': 41, 'county': [None], 'edition': ...  \n",
              "13  {'sequence': 42, 'county': [None], 'edition': ...  \n",
              "14  {'sequence': 40, 'county': [None], 'edition': ...  \n",
              "15  {'sequence': 9, 'county': ['Hennepin', 'Ramsey...  \n",
              "16  {'sequence': 154, 'county': [None], 'edition':...  \n",
              "17  {'sequence': 36, 'county': ['Cascade'], 'editi...  \n",
              "18  {'sequence': 18, 'county': ['Douglas'], 'editi...  \n",
              "19  {'sequence': 30, 'county': ['Cook County'], 'e...  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame.from_dict(json_data)\n",
        "# print(df.head(4))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1snB5GIsI1d_"
      },
      "source": [
        "If we switch the layout of the dataframe, it becomes easier to see how the labels for the dataframe are different from the many items in the items observation. We can try to use the json method `normalize` to flatten out the file into columns. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "jmgkbynYI1d_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['totalItems', 'endIndex', 'startIndex', 'itemsPerPage', 'items'], dtype='object')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.json_normalize(json_data)\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "UkmSFECRI1d_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>county</th>\n",
              "      <th>edition</th>\n",
              "      <th>frequency</th>\n",
              "      <th>id</th>\n",
              "      <th>subject</th>\n",
              "      <th>city</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>end_year</th>\n",
              "      <th>...</th>\n",
              "      <th>language</th>\n",
              "      <th>alt_title</th>\n",
              "      <th>lccn</th>\n",
              "      <th>country</th>\n",
              "      <th>ocr_eng</th>\n",
              "      <th>batch</th>\n",
              "      <th>title_normal</th>\n",
              "      <th>url</th>\n",
              "      <th>place</th>\n",
              "      <th>page</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>[New York]</td>\n",
              "      <td>None</td>\n",
              "      <td>Daily</td>\n",
              "      <td>/lccn/sn83030272/1913-05-04/ed-1/seq-25/</td>\n",
              "      <td>[New York (N.Y.)--Newspapers., New York (State...</td>\n",
              "      <td>[New York]</td>\n",
              "      <td>19130504</td>\n",
              "      <td>The sun. [volume]</td>\n",
              "      <td>1916</td>\n",
              "      <td>...</td>\n",
              "      <td>[English]</td>\n",
              "      <td>[Extra sun, New York sun]</td>\n",
              "      <td>sn83030272</td>\n",
              "      <td>New York</td>\n",
              "      <td>V\\ngg POETRY SECTl GARDENS\\nTHIRD SECTION.\\nNE...</td>\n",
              "      <td>nn_ehrlich_ver02</td>\n",
              "      <td>sun.</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
              "      <td>[New York--New York--New York]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>131</td>\n",
              "      <td>[None]</td>\n",
              "      <td>None</td>\n",
              "      <td>Daily</td>\n",
              "      <td>/lccn/sn83045462/1948-09-26/ed-1/seq-131/</td>\n",
              "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
              "      <td>[Washington]</td>\n",
              "      <td>19480926</td>\n",
              "      <td>Evening star. [volume]</td>\n",
              "      <td>1972</td>\n",
              "      <td>...</td>\n",
              "      <td>[English]</td>\n",
              "      <td>[Star, Sunday star]</td>\n",
              "      <td>sn83045462</td>\n",
              "      <td>District of Columbia</td>\n",
              "      <td>...long limbed,\\nathletic look in\\nUMenea^le*\\...</td>\n",
              "      <td>dlc_2goncharova_ver03</td>\n",
              "      <td>evening star.</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
              "      <td>[District of Columbia--Washington]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>[Fulton]</td>\n",
              "      <td>None</td>\n",
              "      <td>Weekly</td>\n",
              "      <td>/lccn/2020233210/1911-03-16/ed-1/seq-7/</td>\n",
              "      <td>[Atlanta (Ga.)--Newspapers., Christianity--Sou...</td>\n",
              "      <td>[Atlanta]</td>\n",
              "      <td>19110316</td>\n",
              "      <td>The Golden age. [volume]</td>\n",
              "      <td>1920</td>\n",
              "      <td>...</td>\n",
              "      <td>[English]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020233210</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>HE MOST enthusiastic and partial\\nstudent of c...</td>\n",
              "      <td>gu_eridanus_ver02</td>\n",
              "      <td>golden age.</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/202023...</td>\n",
              "      <td>[Georgia--Fulton--Atlanta]</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>[Prince George's]</td>\n",
              "      <td>None</td>\n",
              "      <td>Weekly</td>\n",
              "      <td>/lccn/sn89061521/1938-08-24/ed-1/seq-15/</td>\n",
              "      <td>[Greenbelt (Md.)--Newspapers., Maryland--Green...</td>\n",
              "      <td>[Greenbelt]</td>\n",
              "      <td>19380824</td>\n",
              "      <td>Greenbelt cooperator.</td>\n",
              "      <td>1954</td>\n",
              "      <td>...</td>\n",
              "      <td>[English]</td>\n",
              "      <td>[Greenbelt]</td>\n",
              "      <td>sn89061521</td>\n",
              "      <td>Maryland</td>\n",
              "      <td>Auyust 24, 1938\\nFAVORITE POEMS\\nDear NEIGHBOR...</td>\n",
              "      <td>mdu_annapolis_ver01</td>\n",
              "      <td>greenbelt cooperator.</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8906...</td>\n",
              "      <td>[Maryland--Prince George's--Greenbelt]</td>\n",
              "      <td>PAGE FIFTEEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>[Cook County]</td>\n",
              "      <td>None</td>\n",
              "      <td>Daily (except Sunday and holidays)</td>\n",
              "      <td>/lccn/sn83045487/1912-02-06/ed-1/seq-17/</td>\n",
              "      <td>[Chicago (Ill.)--Newspapers., Illinois--Chicag...</td>\n",
              "      <td>[Chicago]</td>\n",
              "      <td>19120206</td>\n",
              "      <td>The day book. [volume]</td>\n",
              "      <td>1917</td>\n",
              "      <td>...</td>\n",
              "      <td>[English]</td>\n",
              "      <td>[]</td>\n",
              "      <td>sn83045487</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>IKiSKJSSSWPWf\\n0 0\\nThe Mercantile Muse.\\n\"Has...</td>\n",
              "      <td>iune_echo_ver01</td>\n",
              "      <td>day book.</td>\n",
              "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
              "      <td>[Illinois--Cook County--Chicago]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   sequence             county edition                           frequency  \\\n",
              "0        25         [New York]    None                               Daily   \n",
              "1       131             [None]    None                               Daily   \n",
              "2         7           [Fulton]    None                              Weekly   \n",
              "3        15  [Prince George's]    None                              Weekly   \n",
              "4        17      [Cook County]    None  Daily (except Sunday and holidays)   \n",
              "\n",
              "                                          id  \\\n",
              "0   /lccn/sn83030272/1913-05-04/ed-1/seq-25/   \n",
              "1  /lccn/sn83045462/1948-09-26/ed-1/seq-131/   \n",
              "2    /lccn/2020233210/1911-03-16/ed-1/seq-7/   \n",
              "3   /lccn/sn89061521/1938-08-24/ed-1/seq-15/   \n",
              "4   /lccn/sn83045487/1912-02-06/ed-1/seq-17/   \n",
              "\n",
              "                                             subject          city      date  \\\n",
              "0  [New York (N.Y.)--Newspapers., New York (State...    [New York]  19130504   \n",
              "1  [Washington (D.C.)--fast--(OCoLC)fst01204505, ...  [Washington]  19480926   \n",
              "2  [Atlanta (Ga.)--Newspapers., Christianity--Sou...     [Atlanta]  19110316   \n",
              "3  [Greenbelt (Md.)--Newspapers., Maryland--Green...   [Greenbelt]  19380824   \n",
              "4  [Chicago (Ill.)--Newspapers., Illinois--Chicag...     [Chicago]  19120206   \n",
              "\n",
              "                      title  end_year  ...   language  \\\n",
              "0         The sun. [volume]      1916  ...  [English]   \n",
              "1    Evening star. [volume]      1972  ...  [English]   \n",
              "2  The Golden age. [volume]      1920  ...  [English]   \n",
              "3     Greenbelt cooperator.      1954  ...  [English]   \n",
              "4    The day book. [volume]      1917  ...  [English]   \n",
              "\n",
              "                   alt_title        lccn               country  \\\n",
              "0  [Extra sun, New York sun]  sn83030272              New York   \n",
              "1        [Star, Sunday star]  sn83045462  District of Columbia   \n",
              "2                         []  2020233210               Georgia   \n",
              "3                [Greenbelt]  sn89061521              Maryland   \n",
              "4                         []  sn83045487              Illinois   \n",
              "\n",
              "                                             ocr_eng                  batch  \\\n",
              "0  V\\ngg POETRY SECTl GARDENS\\nTHIRD SECTION.\\nNE...       nn_ehrlich_ver02   \n",
              "1  ...long limbed,\\nathletic look in\\nUMenea^le*\\...  dlc_2goncharova_ver03   \n",
              "2  HE MOST enthusiastic and partial\\nstudent of c...      gu_eridanus_ver02   \n",
              "3  Auyust 24, 1938\\nFAVORITE POEMS\\nDear NEIGHBOR...    mdu_annapolis_ver01   \n",
              "4  IKiSKJSSSWPWf\\n0 0\\nThe Mercantile Muse.\\n\"Has...        iune_echo_ver01   \n",
              "\n",
              "            title_normal                                                url  \\\n",
              "0                   sun.  https://chroniclingamerica.loc.gov/lccn/sn8303...   \n",
              "1          evening star.  https://chroniclingamerica.loc.gov/lccn/sn8304...   \n",
              "2            golden age.  https://chroniclingamerica.loc.gov/lccn/202023...   \n",
              "3  greenbelt cooperator.  https://chroniclingamerica.loc.gov/lccn/sn8906...   \n",
              "4              day book.  https://chroniclingamerica.loc.gov/lccn/sn8304...   \n",
              "\n",
              "                                    place          page  \n",
              "0          [New York--New York--New York]                \n",
              "1      [District of Columbia--Washington]             6  \n",
              "2              [Georgia--Fulton--Atlanta]             7  \n",
              "3  [Maryland--Prince George's--Greenbelt]  PAGE FIFTEEN  \n",
              "4        [Illinois--Cook County--Chicago]                \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfpapers = pd.DataFrame.from_dict(json_data['items'])\n",
        "dfpapers.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://chroniclingamerica.loc.gov/lccn/sn83030272/1913-05-04/ed-1/seq-25.json'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfpapers['url'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "H7AxOmrSI1d_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequence\n",
            "county\n",
            "edition\n",
            "frequency\n",
            "id\n",
            "subject\n",
            "city\n",
            "date\n",
            "title\n",
            "end_year\n",
            "note\n",
            "state\n",
            "section_label\n",
            "type\n",
            "place_of_publication\n",
            "start_year\n",
            "edition_label\n",
            "publisher\n",
            "language\n",
            "alt_title\n",
            "lccn\n",
            "country\n",
            "ocr_eng\n",
            "batch\n",
            "title_normal\n",
            "url\n",
            "place\n",
            "page\n"
          ]
        }
      ],
      "source": [
        "for key in dfpapers:\n",
        "    print(key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCl43lyVI1eA"
      },
      "source": [
        "The `.tail()` method will print out just the last (in this case) 6 items in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tib4WgwqReC4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    19130504\n",
              "1    19480926\n",
              "2    19110316\n",
              "3    19380824\n",
              "4    19120206\n",
              "Name: date, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dates = dfpapers[\"date\"]\n",
        "dates.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bFvEUtjA6Jve"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1913-05-04\n",
              "1    1948-09-26\n",
              "2    1911-03-16\n",
              "3    1938-08-24\n",
              "4    1912-02-06\n",
              "5    1915-02-02\n",
              "6    1914-02-04\n",
              "7    1914-03-04\n",
              "8    1908-02-09\n",
              "9    1939-01-22\n",
              "10   1915-12-14\n",
              "11   1948-11-18\n",
              "12   1905-11-19\n",
              "13   1905-11-19\n",
              "14   1905-11-19\n",
              "15   1917-05-31\n",
              "16   1960-04-03\n",
              "17   1954-10-01\n",
              "18   1912-07-28\n",
              "19   1912-08-24\n",
              "Name: date, dtype: datetime64[ns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfpapers[\"date\"] = pd.to_datetime(dfpapers[\"date\"])\n",
        "dfpapers[\"date\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL2alAxxI1eA"
      },
      "source": [
        "The `shape()` method will show how many rows and how many columns are in your dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FK8JCnOJI1eA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 28)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfpapers.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1w0SZAV_vVEy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>end_year</th>\n",
              "      <th>start_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>35.550000</td>\n",
              "      <td>1945.900000</td>\n",
              "      <td>1891.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>42.257948</td>\n",
              "      <td>30.026129</td>\n",
              "      <td>35.256354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1916.000000</td>\n",
              "      <td>1833.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>1917.000000</td>\n",
              "      <td>1854.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>1938.000000</td>\n",
              "      <td>1908.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>40.250000</td>\n",
              "      <td>1972.000000</td>\n",
              "      <td>1911.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>154.000000</td>\n",
              "      <td>1999.000000</td>\n",
              "      <td>1947.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sequence     end_year   start_year\n",
              "count   20.000000    20.000000    20.000000\n",
              "mean    35.550000  1945.900000  1891.200000\n",
              "std     42.257948    30.026129    35.256354\n",
              "min      1.000000  1916.000000  1833.000000\n",
              "25%      9.000000  1917.000000  1854.000000\n",
              "50%     21.000000  1938.000000  1908.500000\n",
              "75%     40.250000  1972.000000  1911.000000\n",
              "max    154.000000  1999.000000  1947.000000"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfpapers.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTqWqrSvI1eB"
      },
      "source": [
        "## Reflection and Writing\n",
        "In this exercise, you queried an API from Chronicling America and pulled in files that included the search term \"poetry.\" Those files, then, reshaped and made slightly more tidy by highlighting the \"keys\" to the dictionary, and then taking one small section of the dictionary and turning it into a dataframe. \n",
        "\n",
        "Look back over the notebook and do the following: \n",
        "\n",
        "\n",
        "1.   Return to the section \"Reading text in a dataframe.\" Read through some of the entries. Create a new text cell and explain what kind of \"data cleaning\" you would recommend to prepare the text for analysis. How can you take into consideration Munoz and Rawson's article? What makes the data \"messy\"? What messiness should remain? What messiness should be repaired? What messiness should be removed? \n",
        "2.    Go to the top of the Chronicling America section. Make a copy of the search query and try replacing the term \"poetry\" (the parameter of the search argument) with another one. What were the results? \n",
        "3.   What changes when you rerun the activity besides the results? Do you need to make any changes to the next cells for them to run? \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JPUP3e6HqHX3"
      },
      "source": [
        "1.   Return to the section \"Reading text in a dataframe.\" Read through some of the entries. Create a new text cell and explain what kind of \"data cleaning\" you would recommend to prepare the text for analysis. \n",
        "\n",
        "The 'content' or ocr_eng value in the data is the text of the newspaper created from optical character recognition tools. This text would be the most likely to process using a variety of tools depending on the questions of the researchers. For example spaces and line breaks and the character combinations that represent them might be removed. As well a tokenization process, removal of stop words, lemmatization, and more could all be undertaken. But depending on the interests of the researchers and the communities of interest that they are wishing to engage, they may take additional steps to interact with the data. For example each entry in the results also includes the source URL of the newspaper json which points to a PDF of the newspaper page. With a quick look at the first value [The Sun](https://chroniclingamerica.loc.gov/data/batches/nn_ehrlich_ver02/data/sn83030272/0020653994A/1913050401/0866.pdf) you would quickly find that the word \"POULTRY\" was misinterpretted by the OCR as \"POETRY\" and should not have even been included in the data set! \n",
        "\n",
        "So the image which is still 'messy' has tremendous value when considering the processing tools and the choices they make.\n",
        "\n",
        "2.    Go to the top of the Chronicling America section. Make a copy of the search query and try replacing the term \"poetry\" (the parameter of the search argument) with another one. What were the results? \n",
        "\n",
        "Switching to the search term 'walrus' still produced 20 entries, which due to the fact that each json request returns a value describing how many 'totalItems' there are, in this case 42632, but also describes that 'itemsPerPage' is 20. If you wished to gather the data for all 42632 items you would have to create multiple requests looping through 20 at a time and attaching and incrementing the '&page=#' to the url. This of course would take some time, but hopefully would not timeout!\n",
        "\n",
        "3.   What changes when you rerun the activity besides the results? Do you need to make any changes to the next cells for them to run? \n",
        "\n",
        "No particular changes are required other than the additional text processing experiments created above and the addition of the URL to the sample.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
